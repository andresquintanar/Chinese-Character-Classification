# -*- coding: utf-8 -*-
"""quintanar_andres_finalproject_p1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uJVmmDBB5SikknrBTs6YsK9mA6ad1KBb
"""

# Andres Quintanar 
# Chinese Character Classification Project
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Reshape
from keras.utils import np_utils
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import matplotlib.pyplot as plt
import random
import pandas as pd
import seaborn as sb
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 1. Write code to train a NN model which classifies the Chinese numbers dataset.
df = pd.read_csv("/chineseMNIST.csv")

X = df.iloc[:,:4096]
y = df.iloc[:,4097]
indicies = {'零':1, '一':2, '二': 3, '三':4, '四':5, '五':6, '六':7, '七':8, '八':9, '九':10, 
             '十':11, '百':12,'千': 13,'万':14,'亿':15}

data = np.array(X)
X_data = []

for d in data:
    X_data.append(d.reshape(64,64))

X_data = np.array(X_data)

y_array = np.array(y)
Y_array1 = []
for i in range(0,15000):
    something = np.array(indicies[y_array[i]])
    Y_array1.append(something)

y_data = pd.DataFrame(Y_array1)

# 2. Plots the count of each Chinese number in dataset 
word_dict = {0:'零', 1:'一', 2: '二', 3:'三', 4:'四', 5:'五', 6:'六', 7:'七', 8:'八', 9:'九', 
             10:'十', 100: '百', 1000:'千', 10000:'万',100000000:'亿'}
values = word_dict.values()
prop = fm.FontProperties(fname = '/chinese.ttf')

plt.figure(1)
ax = sb.countplot(x="label", data = df)
ax.set_xticklabels(values,
		fontproperties = prop, fontsize=18)
plt.show()

# 3. Vizualizes 25 random chracters from the dataset
English_dict = {'零':0, '一':1, '二': 2, '三':3, '四':4, '五':5, '六':6, '七':7, '八':8, '九':9, 
             '十':10, '百':100, '千':1000,'万':10000,'亿':100000000}
for image_number in range (0,25):
  rand_int = random.randint(0, 14999)
  test_sample = np.array(X.iloc[rand_int,:]).reshape(64,64)
  plt.imshow(test_sample, cmap= "gray")
  stored_y = y.iloc[rand_int]
  plt.title(stored_y,
		fontproperties = prop, fontsize=18)
  plt.xlabel(int(English_dict[stored_y]), fontsize=18)
  plt.show()

# 4. Scale the pixel values
X_data = X_data/255

#5. Partition the dataset into train and test sets
X_train, X_test, y_train, y_test = \
  train_test_split(X_data, y_data, test_size=0.3, random_state=2022, stratify = y)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

#6. A neural network model using Keras layers 
# Inititate Keras models
model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=(64,64)))
model.add(keras.layers.Dense(100, activation= "relu"))
model.add(keras.layers.Dense(100, activation = "relu"))
# Add a dense output layer
model.add(keras.layers.Dense(16, activation = "softmax"))

#7.) Display model summary 
model.summary()

#8. Model loss function
model.compile(loss = "sparse_categorical_crossentropy", optimizer = "sgd", metrics = ["accuracy"])

#9. Trains the model for 25 epochs
h = model.fit(X_train, y_train, epochs = 25, verbose =1)

#10. Loss and Accuracy Curves

# Plot the loss curve 

pd.DataFrame(h.history).plot()
plt.show()

# Display the accuracy of the model
accuracy_train = model.evaluate(X_train, y_train)
print("The accuracy of the train model is: ", accuracy_train)

accuracy_test = model.evaluate(X_test, y_test)
print("The accuracy of the test model is: ", accuracy_test)

#11. Vizualize the actual and predicted labels for the first 30 images
Chinese_dict = {1:'零', 2:'一', 3: '二', 4:'三', 5:'四', 6:'五', 7:'六', 8:'七', 9:'八', 10:'九', 
             11:'十', 12: '百', 13:'千', 14:'万',15:'亿'}
y_test = np.array(y_test)
for j in range (0,30):
  y_pred = model.predict(X_test)
  y_pred = np.argmax(y_pred, axis=1)
  test_sample = np.array(X_test[j]).reshape(64,64)
  plt.imshow(test_sample, cmap= "gray")
  prediction = int(y_pred[j])
  actual = int(y_test[j])
  plt.title("The predicted Chinese symbol is: "+str(Chinese_dict[prediction])+" The actual Chinese symbol is: "+str(Chinese_dict[actual]),
		fontproperties = prop, fontsize=16)
  plt.show()

#12. Vizualizes 30 random misclassfied images
pred = model.predict(X_test)

# Convert the predictions into label index
pred_classes = np.argmax(pred, axis=1)
failed_indices = []
idx = 0

# Get list of all the failed indices
for t in y_test:
    if t[0] != pred_classes[idx]:
        failed_indices.append(idx)
    idx = idx + 1

plt.figure(figsize=[15,15])
# Plot random 30 misclassified images
for i in range (30):
    random_select = np.random.randint(0, len(failed_indices))
    failed_index = failed_indices[random_select]
    plt.subplot(5, 6, i+1).imshow(X_test[failed_index])
    plt.subplot(5, 6, i+1).set_title("True: %s \nPredict: %s" %
                      (Chinese_dict[y_test[failed_index,0]],
                       Chinese_dict[pred_classes[failed_index]]),fontproperties = prop, fontsize=16)
    plt.subplot(5, 6, i+1).axis('off')